{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "airplane : 0\n",
    "automobile : 1\n",
    "bird : 2\n",
    "cat : 3\n",
    "deer : 4\n",
    "dog : 5\n",
    "frog : 6\n",
    "horse : 7\n",
    "ship : 8\n",
    "truck : 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.optim.adamw import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "from wolf.data import load_datasets, get_batch, preprocess, postprocess\n",
    "from wolf import WolfModel\n",
    "from wolf.utils import total_grad_norm\n",
    "from wolf.optim import ExponentialScheduler\n",
    "\n",
    "from experiments.options import parse_args\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_master(rank):\n",
    "    return rank <= 0\n",
    "\n",
    "\n",
    "def is_distributed(rank):\n",
    "    return rank >= 0\n",
    "\n",
    "def logging(info, logfile=None):\n",
    "    print(info)\n",
    "    if logfile is not None:\n",
    "        print(info, file=logfile)\n",
    "        logfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataloader(args, train_data, val_data):\n",
    "    if is_distributed(args.rank):\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_data, rank=args.rank,\n",
    "                                                                        num_replicas=args.world_size,\n",
    "                                                                        shuffle=True)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "    train_loader = DataLoader(train_data, batch_size=args.batch_size,\n",
    "                              shuffle=(train_sampler is None), sampler=train_sampler,\n",
    "                              num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "    if is_master(args.rank):\n",
    "        eval_batch = args.eval_batch_size\n",
    "        val_loader = DataLoader(val_data, batch_size=eval_batch, shuffle=False,\n",
    "                                num_workers=args.workers, pin_memory=True)\n",
    "    else:\n",
    "        val_loader = None\n",
    "\n",
    "    return train_loader, train_sampler, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(args):\n",
    "    def check_dataset():\n",
    "        if dataset == 'cifar10':\n",
    "            assert image_size == 32, 'CIFAR-10 expected image size 32 but got {}'.format(image_size)\n",
    "        elif dataset.startswith('lsun'):\n",
    "            assert image_size in [128, 256]\n",
    "        elif dataset == 'celeba':\n",
    "            assert image_size in [256, 512]\n",
    "        elif dataset == 'imagenet':\n",
    "            assert image_size in [64, 128, 256]\n",
    "\n",
    "    dataset = args.dataset\n",
    "    if args.category is not None:\n",
    "        dataset = dataset + '_' + args.category\n",
    "    image_size = args.image_size\n",
    "    check_dataset()\n",
    "\n",
    "    nc = 3\n",
    "    args.nx = image_size ** 2 * nc\n",
    "    n_bits = args.n_bits\n",
    "    args.n_bins = 2. ** n_bits\n",
    "    args.test_k = 1\n",
    "\n",
    "    model_path = args.model_path\n",
    "    args.checkpoint_name = os.path.join(model_path, 'checkpoint')\n",
    "\n",
    "    result_path = os.path.join(model_path, 'images')\n",
    "    args.result_path = result_path\n",
    "    data_path = args.data_path\n",
    "\n",
    "    if is_master(args.rank):\n",
    "        if not os.path.exists(model_path):\n",
    "            os.makedirs(model_path)\n",
    "        if not os.path.exists(result_path):\n",
    "            os.makedirs(result_path)\n",
    "        if args.recover < 0:\n",
    "            args.log = open(os.path.join(model_path, 'log.txt'), 'w')\n",
    "        else:\n",
    "            args.log = open(os.path.join(model_path, 'log.txt'), 'a')\n",
    "    else:\n",
    "        args.log = None\n",
    "\n",
    "    args.cuda = torch.cuda.is_available()\n",
    "    random_seed = args.seed + args.rank if args.rank >= 0 else args.seed\n",
    "    if args.recover >= 0:\n",
    "        random_seed += random.randint(0, 1024)\n",
    "    logging(\"Rank {}: random seed={}\".format(args.rank, random_seed), logfile=args.log)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    device = torch.device('cuda', args.local_rank) if args.cuda else torch.device('cpu')\n",
    "    if args.cuda:\n",
    "        torch.cuda.set_device(device)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    args.world_size = int(os.environ[\"WORLD_SIZE\"]) if is_distributed(args.rank) else 1\n",
    "    logging(\"Rank {}: \".format(args.rank) + str(args), args.log)\n",
    "\n",
    "    train_data, val_data = load_datasets(dataset, image_size, data_path=data_path)\n",
    "    train_index = np.arange(len(train_data))\n",
    "    np.random.shuffle(train_index)\n",
    "    val_index = np.arange(len(val_data))\n",
    "\n",
    "    if is_master(args.rank):\n",
    "        logging('Data size: training: {}, val: {}'.format(len(train_index), len(val_index)))\n",
    "\n",
    "    if args.recover >= 0:\n",
    "        params = json.load(open(os.path.join(model_path, 'config.json'), 'r'))\n",
    "    else:\n",
    "        params = json.load(open(args.config, 'r'))\n",
    "        json.dump(params, open(os.path.join(model_path, 'config.json'), 'w'), indent=2)\n",
    "\n",
    "    wolf = WolfModel.from_params(params)\n",
    "    wolf.to_device(device)\n",
    "    args.device = device\n",
    "    \n",
    "    if args.recover >= 0:\n",
    "        wolf = WolfModel.load(args.model_path, args.device, 0)\n",
    "\n",
    "    return args, (train_data, val_data), (train_index, val_index), wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=False\n",
    "\n",
    "def eval(args, val_loader, wolf):\n",
    "    wolf.eval()\n",
    "    wolf.sync()\n",
    "    gnll = 0\n",
    "    nent = 0\n",
    "    kl = 0\n",
    "    num_insts = 0\n",
    "    device = args.device\n",
    "    n_bits = args.n_bits\n",
    "    n_bins = args.n_bins\n",
    "    nx = args.nx\n",
    "    test_k = args.test_k\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for step, (data, y) in enumerate(val_loader):\n",
    "        batch_size = len(data)\n",
    "        data = data.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            wolf.loss(data, y=y, n_bits=n_bits, nsamples=test_k)\n",
    "#         print('shape is ', attns.shape)\n",
    "        \n",
    "#         del attns\n",
    "#         gc.collect()\n",
    "#         size_bool = True\n",
    "#         for attn_idx in range(len(attns_)-1):\n",
    "#             size_bool = (size_bool and (attns_[attn_idx].shape == attns_[attn_idx].shape))\n",
    "#         if debug:\n",
    "#             if size_bool:\n",
    "#                 print('the length of attentions is {}; the shape of attention is {}'.format(len(attns_), attns_[0].shape))\n",
    "#             else:\n",
    "#                 print('Size not matched')\n",
    "#         gnll += loss_gen.sum().item()\n",
    "#         kl += loss_kl.sum().item()\n",
    "#         nent += loss_dequant.sum().item()\n",
    "#         num_insts += batch_size\n",
    "        \n",
    "#         results.append((data.to('cpu'), y.to('cpu'), attns.to('cpu')))\n",
    "        results.append((data.to('cpu'), y.to('cpu')))\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print('Step: ', step)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "#     gnll = gnll / num_insts\n",
    "#     nent = nent / num_insts\n",
    "#     kl = kl / num_insts\n",
    "#     nll = gnll + kl + nent + np.log(n_bins / 2.) * nx\n",
    "#     bpd = nll / (nx * np.log(2.0))\n",
    "#     nepd = nent / (nx * np.log(2.0))\n",
    "#     logging('Avg  NLL: {:.2f}, KL: {:.2f}, NENT: {:.2f}, BPD: {:.4f}, NEPD: {:.4f}'.format(\n",
    "#         nll, kl, nent, bpd, nepd), args.log)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    args, (train_data, val_data), (train_index, val_index), wolf = setup(args)\n",
    "\n",
    "    train_loader, train_sampler, val_loader = init_dataloader(args, train_data, val_data)\n",
    "\n",
    "    return eval(args, val_loader, wolf), wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'rank': -1,\n",
    " 'local_rank': 0,\n",
    " 'config': 'experiments/configs/cifar10/glow/glow-cat-uni.json',\n",
    " 'batch_size': 256,\n",
    " 'eval_batch_size': 512,\n",
    " 'batch_steps': 2,\n",
    " 'init_batch_size': 1024,\n",
    " 'epochs': 100,\n",
    " 'valid_epochs': 10,\n",
    " 'seed': 65537,\n",
    " 'train_k': 1,\n",
    " 'log_interval': 10,\n",
    " 'lr': 0.001,\n",
    " 'warmup_steps': 50,\n",
    " 'lr_decay': 0.999997,\n",
    " 'beta1': 0.9,\n",
    " 'beta2': 0.999,\n",
    " 'eps': 1e-08,\n",
    " 'weight_decay': 1e-06,\n",
    " 'amsgrad': False,\n",
    " 'grad_clip': 0.0,\n",
    " 'dataset': 'cifar10',\n",
    " 'category': None,\n",
    " 'image_size': 32,\n",
    " 'workers': 4,\n",
    " 'n_bits': 8,\n",
    " 'model_path': 'experiments/models/glow/cifar_linear_model/',\n",
    " 'data_path': 'experiments/data/cifar_data',\n",
    " 'recover': 1,\n",
    "}\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank -1: random seed=66096\n",
      "Rank -1: Namespace(amsgrad=False, batch_size=256, batch_steps=2, beta1=0.9, beta2=0.999, category=None, checkpoint_name='experiments/models/glow/cifar_linear_model/checkpoint', config='experiments/configs/cifar10/glow/glow-cat-uni.json', cuda=True, data_path='experiments/data/cifar_data', dataset='cifar10', epochs=100, eps=1e-08, eval_batch_size=512, grad_clip=0.0, image_size=32, init_batch_size=1024, local_rank=0, log=<_io.TextIOWrapper name='experiments/models/glow/cifar_linear_model/log.txt' mode='a' encoding='UTF-8'>, log_interval=10, lr=0.001, lr_decay=0.999997, model_path='experiments/models/glow/cifar_linear_model/', n_bins=256.0, n_bits=8, nx=3072, rank=-1, recover=1, result_path='experiments/models/glow/cifar_linear_model/images', seed=65537, test_k=1, train_k=1, valid_epochs=10, warmup_steps=50, weight_decay=1e-06, workers=4, world_size=1)\n",
      "Files already downloaded and verified\n",
      "Data size: training: 50000, val: 10000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'experiments/models/glow/cifar_linear_model/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2b94cf4cf17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwolf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-5d4830f0a9ce>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwolf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ef7e5a3444c1>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiments/models/glow/cifar_linear_model/config.json'"
     ]
    }
   ],
   "source": [
    "results, wolf = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(args, img, y1, y2, wolf):\n",
    "    print('reconstruct')\n",
    "    wolf.eval()\n",
    "    batch = 1\n",
    "    nsamples = 15\n",
    "\n",
    "#     index = np.arange(len(data))\n",
    "#     np.random.shuffle(index)\n",
    "#     img, y = get_batch(data, index[:batch])\n",
    "    img = img.to(args.device)\n",
    "    y1 = y1.to(args.device)\n",
    "    y2 = y2.to(args.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_size = (3, args.image_size, args.image_size)\n",
    "        _, epsilon1 = wolf.encode(img, y=y1, n_bits=args.n_bits, nsamples=nsamples, random=True)\n",
    "        epsilon1 = epsilon1.view(batch * nsamples, *image_size)\n",
    "        z1 = wolf.encode_global(img, y=y1, n_bits=args.n_bits, nsamples=nsamples, random=True)\n",
    "        z1 = z1.view(batch * nsamples, z1.size(2))\n",
    "        # [batch, nsamples, c, h, w]\n",
    "        img_recon1 = wolf.decode(epsilon1, z=z1, n_bits=args.n_bits).view(batch, nsamples, *image_size)\n",
    "        \n",
    "        _, epsilon2 = wolf.encode(img, y=y2, n_bits=args.n_bits, nsamples=nsamples, random=True)\n",
    "        epsilon2 = epsilon2.view(batch * nsamples, *image_size)\n",
    "        z2 = wolf.encode_global(img, y=y2, n_bits=args.n_bits, nsamples=nsamples, random=True)\n",
    "        z2 = z2.view(batch * nsamples, z2.size(2))\n",
    "        # [batch, nsamples, c, h, w]\n",
    "        img_recon2 = wolf.decode(epsilon2, z=z2, n_bits=args.n_bits).view(batch, nsamples, *image_size)\n",
    "        \n",
    "        # [batch, 1, c, h, w]\n",
    "        img = postprocess(preprocess(img, args.n_bits), args.n_bits).unsqueeze(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3)\n",
    "    img_cpu = img.cpu()\n",
    "    img_recon1_cpu = img_recon1.cpu()\n",
    "    img_recon2_cpu = img_recon2.cpu()\n",
    "\n",
    "    axs[0].imshow(img_cpu[0][0].permute(1, 2, 0))\n",
    "    axs[1].imshow(img_recon1_cpu[0][0].permute(1, 2, 0))\n",
    "    axs[2].imshow(img_recon2_cpu[0][0].permute(1, 2, 0))\n",
    "    print('Recon1 and Origin: ', torch.norm(img_recon1_cpu[0][0] - img_cpu[0][0]))\n",
    "    print('Recon2 and Origin: ', torch.norm(img_recon2_cpu[0][0] - img_cpu[0][0]))\n",
    "    print('Recon1 and Recons: ', torch.norm(img_recon1_cpu[0][0] - img_recon2_cpu[0][0]))\n",
    "    print('eps shape: ', epsilon1.shape)\n",
    "    print('z shape: ', z1.shape)\n",
    "    print('z1 and z2: ', torch.norm(z1 - z2))\n",
    "    print('eps1 and eps2: ', torch.norm(epsilon1 - epsilon2))\n",
    "\n",
    "    # [batch, nsamples + 1, c, h, w] -> [batch*(nsamples + 1), c, h, w]\n",
    "#     comparison = torch.cat([img, img_recon], dim=1).view(-1, *image_size).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruct\n",
      "torch.Size([1, 15, 64])\n",
      "torch.Size([1, 15, 64])\n",
      "torch.Size([1, 15, 64])\n",
      "torch.Size([1, 15, 64])\n",
      "Recon1 and Origin:  tensor(0.)\n",
      "Recon2 and Origin:  tensor(0.0068)\n",
      "Recon1 and Recons:  tensor(0.0068)\n",
      "eps shape:  torch.Size([15, 3, 32, 32])\n",
      "z shape:  torch.Size([15, 64])\n",
      "z1 and z2:  tensor(7.4758, device='cuda:0')\n",
      "eps1 and eps2:  tensor(84.9050, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_1, label_1 = results[0]\n",
    "y_1_ = results[0][1]\n",
    "reconstruct(args, data_1[9].unsqueeze(0), label_1[0].unsqueeze(0), label_1[2].unsqueeze(0), wolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(args, epoch, wolf):\n",
    "    logging('sampling', args.log)\n",
    "    wolf.eval()\n",
    "    n = 64 if args.image_size > 128 else 256\n",
    "    nrow = int(math.sqrt(n))\n",
    "    taus = [0.7, 0.8, 0.9, 1.0]\n",
    "    start_time = time.time()\n",
    "    image_size = (3, args.image_size, args.image_size)\n",
    "    for t in taus:\n",
    "        imgs = wolf.synthesize(n, image_size, tau=t, n_bits=args.n_bits, device=args.device)\n",
    "#         plt.imshow(imgs)\n",
    "        image_file = 'sample{}.t{:.1f}.png'.format(epoch, t)\n",
    "        save_image(imgs, os.path.join(args.result_path, image_file), nrow=nrow)\n",
    "    logging('time: {:.1f}s'.format(time.time() - start_time), args.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling\n",
      "time: 4.3s\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample(args, 222, wolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_cat(args, epoch, wolf, label):\n",
    "    logging('sampling based on cat', args.log)\n",
    "    wolf.eval()\n",
    "    n = 64 if args.image_size > 128 else 256\n",
    "    nrow = int(math.sqrt(n))\n",
    "    taus = [0.7, 0.8, 0.9, 1.0]\n",
    "    image_size = (3, args.image_size, args.image_size)\n",
    "    device = args.device\n",
    "#     label = torch.Tensor(label).to(device).long()\n",
    "    label = label.to(device)\n",
    "    print(label)\n",
    "    \n",
    "    for t in taus:\n",
    "        epsilon = torch.randn(n, *image_size, device=device)\n",
    "        epsilon = epsilon * t\n",
    "        z = wolf.encode_global(epsilon, label)\n",
    "        z = z.view(n, z.size(2))\n",
    "        imgs = wolf.decode(epsilon, z)\n",
    "        image_file = 'sample{}.t{:.1f}.png'.format(epoch, t)\n",
    "        save_image(imgs, os.path.join(args.result_path, image_file), nrow=nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling based on cat\n",
      "tensor([1], device='cuda:0')\n",
      "torch.Size([256, 1, 64])\n",
      "torch.Size([256, 1, 64])\n",
      "torch.Size([256, 1, 64])\n",
      "torch.Size([256, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    synthesize_cat(args, 224, wolf, label_1[6].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDiscriminator(\n",
       "  (embed): Embedding(10, 64)\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wolf.core.discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wolf",
   "language": "python",
   "name": "wolf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
